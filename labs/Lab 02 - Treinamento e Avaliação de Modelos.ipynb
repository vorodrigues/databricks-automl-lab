{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1abf9508-e1c8-44b3-9855-94bf5e5b52ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](https://github.com/vorodrigues/databricks-automl-lab/blob/main/img/header-automl.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4c20fc3-9705-4d13-8115-f9717f88570a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Lab 02 - Treinamento e Avaliação de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bef20fa-4d25-4850-a03c-d714405f5faa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercício 02.01 - Treinamento de modelos com AutoML\n",
    "\n",
    "Após explorar e preparar nossos dados estamos prontos para começar a treinar nossos modelos usando o **AutoML**.\n",
    "\n",
    "Para isso, vamos criar nosso experimento!\n",
    "\n",
    "Siga os passos abaixo:\n",
    "\n",
    "- No menu principal, selecione **Experiments**\n",
    "- No cartão **Classification**, clique em **Start training**\n",
    "- Em **Cluster**, selecione o seu cluster\n",
    "- Em **Input training dataset**, clique em **Browse** e selecione a tabela **fraud_abt**\n",
    "- Em **Prediction target**, selecione **fraud_report**\n",
    "- Clique em **Advanced Configuration**\n",
    "  - Em **Evaluation metric**, selecione **ROC/AUC**\n",
    "  - Em **Experiment directory**, digite o caminho de um diretório compartilhado ao qual o grupo do cluster tenha acesso\n",
    "  - Em **Timeout (minutes)**, digite **10**\n",
    "  - Em **Positive label**, digite **1**\n",
    "- Clique em **Start AutoML**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8459dff8-88b4-47a8-b0cc-36ad734d5972",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercício 02.02 - Analisando o notebook de exploração\n",
    "\n",
    "- Clique em **View data exploration notebook**\n",
    "- Desça até **Profiling Results**\n",
    "- Analise o **Profiling Report**\n",
    "  - Use a sessão **Overview** para dados faltantes (missing), registros duplicados e alertas gerados\n",
    "  - Use a sessão **Variables** para avaliar se as distribuições das variáveis estão normais\n",
    "  - Use a tabela **Correlations** para identificar colunas com alta correlação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39aa8d98-6f07-4cfa-a802-ff7493ea8f9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercício 02.03 - Avaliando os modelos\n",
    "\n",
    "- Clique no **ícone do gráfico**\n",
    "- Clique no **ícone do olho** e selecione **Show all runs**\n",
    "- Avalie a performance dos modelos\n",
    "  - São criados automaticamente gráficos para diversas métricas de performance (F1, acuracidade, precisão, recall, entre outras) em cada uma das bases – treino (training), validação (val) e teste (test)\n",
    "- No canto superior direito, clique em **Add chart** e selecione **Scatter plot**\n",
    "  - Em **X axis**, selecione **training_roc_auc**\n",
    "  - Em **Y axis**, selecione **test_roc_auc**\n",
    "  - Clique em **Add chart**\n",
    "\n",
    "Este gráfico nos permite comparar a performance dos modelos nas bases utilizadas durante os seus treinamentos e também em dados que o modelo não havia visto antes. Isso nos permite entender se o modelo está **generalizando** bem, ou seja, se ele é capaz de reproduzir sua performance do treinamento no mundo real. Vamos buscar os modelos que possuem a maior performance, porém com a menor diferença possível entre treino e teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0521cf6-2e85-4a08-8419-6b9caf05130e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercício 02.04 - Visualizando o melhor modelo\n",
    "\n",
    "- No gráfico, clique no ponto que representa o melhor modelo\n",
    "- No cartão, clique no nome do modelo\n",
    "\n",
    "Veja que todas as informações do modelo se encontram disponíveis, desde os parâmetros utilizados  e métricas de performance nas diversas bases, até o notebook criado pelo **AutoML** para treinar o modelo e artefatos gerados. Isso garante máxima transparência ao processo e permite com que vocês façam alterações adicionais, caso desejem.\n",
    "\n",
    "Aficionalmente, siga os passos abaixo:\n",
    "\n",
    "- Clique no notebook disponível em **Source** para visualizar o código\n",
    "- Na tela do exeperimento, clique na aba **Artifacts** para visualizar as especificações do modelo, binários, dependências e outros artefatos necessários para a sua execução em produção\n",
    "\n",
    "**Observação**:\n",
    "- Alguns artefatos são gerados apenas para o modelo campeão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f2a2cb7-4908-4a33-94d5-9a9d48efc356",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercício 02.05 - Inferência\n",
    "\n",
    "- Na célula abaixo, preencha o valor da variável `db`\n",
    "- Na aba **Artifacts**, copie o código em **Predict on a Spark DataFrame** e cole na célula vazia na sequência\n",
    "- Execute todas as células abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5406918b-b69b-4380-ab62-e9c26f9790b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table('vr_demo.fraud.fraud_abt_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c905abc3-5e2b-4c3e-97fa-058f2f876055",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pyspark.sql.functions import struct, col\n",
    "logged_model = 'runs:/21b4d7592a814a7ab6381f13c8054eaf/model'\n",
    "\n",
    "# Load model as a Spark UDF. Override result_type if the model does not return double values.\n",
    "loaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model)\n",
    "\n",
    "# Predict on a Spark DataFrame.\n",
    "df = df.withColumn('predictions', loaded_model(struct(*map(col, df.columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98f3f44d-ba0c-465c-b369-c08b8478b22d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "330fed24-c347-4b8b-a382-3cfe3ff679be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Observações:**\n",
    "\n",
    "- O exemplo de inferência acima pode ser utilizado para fins de validação dos modelos gerados pelo AutoML, porém não é recomendada a sua utilização em produção.\n",
    "- Para projetos produtivos, é recomendado:\n",
    "  - Mover o experimento para um diretório seguro e ajustar as permissões para evitar alterações indesejadas\n",
    "  - Registrar o modelo no **Unity Catalog**\n",
    "  - Atribuir **aliases** para identificar modelos em validação e produção, por exemplo\n",
    "  - Referenciar os modelos do **Unity Catalog** nos jobs de inferência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9524f1c-f32b-4930-9569-fc55040fd0f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Parabéns!**\n",
    "\n",
    "Você concluiu o treinamento e avaliação de modelos. Agora você já possui os conceitos básicos para criar seus próprios modelos com agilidade, mas também aproveitando  boas práticas e técnicas de otimização embutidas no **Databricks AutoML**."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2588019255281985,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Lab 02 - Treinamento e Avaliação de Modelos",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
